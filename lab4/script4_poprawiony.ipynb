{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Własne środowisko"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "metadata": {}
   },
   "source": [
    "### Autorzy: Jakub Kot, Dawid Małecki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cel ćwiczenia\n",
    "Stworzenie własnego środowiska do nauczania ze wzmocnieniem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opis problemu\n",
    "Zadanie polega na stworzeniu własnego środowiska, a następnie dodania do niego agenta, który będzie chciał zmaksymalizować funkcję nagrody w środowisku. Agent będzie dokonywał decyzji o wyborze akcji na podstawie obserwacji ze środowiska. Po zakończeniu pojedynczej gry agent będzie uczył się na podstawie swoich doświadczeń wykorzystując uczenie przez wzmacnianie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozwiązanie problemu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimplementowane przez nas środowisko jest grą w czołgi. Na planszy co chwile pojawiają się czołgi przeciwnika. Agent musi na bierząco niszczyć czołgi, aby zdobywać punkty. W przypadku trafienia przez czołg przeciwnika, agent traci jedno życie. Gra kończy się w momencie, gdy agent straci wszystkie trzy życia.\n",
    "\n",
    "Środowisko, aczkolwiek dyskretne, jest stosunkowo duże, gdyż użyta plansza ma wymiary 15x15, a dodatkowo czołgi mogą poruszać się co jedną szóstą pola w każdym kierunku oraz wystrzeliwać pociski. W wypadku kolizji dwóch pocisków, oba znikają. Kolizja dwóch czołgów nie pozwala na przejście przez siebie nawzajem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Game](https://i.imgur.com/YE0HrWK.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czerwony czołg należy do agenta, zielone czołgi to przeciwnicy, brązowe kulki to pociski. Przeciwnicy mogą się pojawiać w kilkunastu wyznaczonych miejscach w okolicach brzegu planszy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obserwacja, którą dokonuje agent, dostarcza informacji na temat położenia najbliższego przeciwnika, obecnej rotacji czołgu, najbliższych przeszkód oraz nadlatujących pocisków. Na podstawie tych informacji podejmuje decyzje o ruchu i strzale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastosowana przez nas metoda uczenia to Deep Q-Learning. Wykorzystana sieć neuronowa ma 2 warstwy ukryte po 512 neuronów. Funkcja straty to błąd średniokwadratowy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strategia przyjęta przez agenta okazała się stosunkowo prosta. Agent cierpliwie czeka na miejscu startowym (gdzie jest chroniony z dwóch stron przez ściany) i cierpliwie czeka na pojawienie się przeciwnika. Strategia ta jest stosunkowo skuteczna, jednak jeśli żaden z przeciwników nie pojawi się w zasięgu strzału przez odpowiednio długi czas, gra zostaje zakończona. Miało to na celu zmuszenie agenta do podejmowania akcji, jednak ostatecznie nie udało się nam zmusić do tego agenta.\n",
    "\n",
    "Nadal jednak wyniki agenta są stosunkowo dobre, co pokazuje poniższy wykres (pomimo ustawienia maksymalnej prędkości toczenia się gry, każda gra jest stosunkowo długa, więc wyniki zostały zaprezentowane na niewielkiej liczbie gier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Results](https://i.imgur.com/24o6jOd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Większość eksperymentów przynosiła najlepsze wyniki w okolicach 25 punktów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wnioski:\n",
    "- Stworzenie własnego środowiska do uczenia ze wzmocnieniem jest stosunkowo proste.\n",
    "- Dobranie odpowiednich obserwacji oraz funkcji nagrody dla agenta jest nie tylko bardzo ważne, ale też trudne.\n",
    "- Uczenie przez wzmacnianie jest stosunkowo skomplikowanym zagadnieniem, które często polega na długim procesie dobierania i dostosowywania hiperparametrów oraz cierpliwości.\n",
    "- Dalsze usprawnienia mogłyby polegać na bardziej skomplikowanej strategii agenta, na przykład nauczeniu go poruszania się po planszy w poszukiwaniu przeciwników, a nie czekaniu na nich w miejscu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kod źródłowy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kod gry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kod do najczystszych nie należy, gdyż oryginalnym pomysłem było stworzenie dwóch agentów, którzy mieliby walczyć ze soba nawzajem. Pomysł okazał się jednak stosunkowo trudny, dlatego gra została przekształcona w grę jednoosobową. Kod źródłowy nadal jednak posiada fragmenty kodu, które odpowiadały za drugiego gracza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "from enum import Enum\n",
    "import random\n",
    "\n",
    "PIXEL_SIZE = 6\n",
    "BLOCK_SIZE = PIXEL_SIZE*6\n",
    "BULLET_SIZE = PIXEL_SIZE*2\n",
    "from PIL import Image\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "MAP_SIZE_X = 0\n",
    "MAP_SIZE_Y = 0\n",
    "\n",
    "class Direction(Enum):\n",
    "    UP = (0, -PIXEL_SIZE)\n",
    "    DOWN = (0, PIXEL_SIZE)\n",
    "    LEFT = (-PIXEL_SIZE, 0)\n",
    "    RIGHT = (PIXEL_SIZE, 0)\n",
    "\n",
    "class Utils:\n",
    "    def init_map(map_name):\n",
    "        # open txt file with map\n",
    "        # read character by character, if the character is \"#\" then create an obstacle\n",
    "        # if it is \"-\" then do nothing\n",
    "        # if it is \"1\" then create a tank 1\n",
    "        # if it is \"2\" then create a tank 2\n",
    "        # if it is \"3\" then create a tank bot spawner\n",
    "        # if it is \"\\n\" then go to the next line\n",
    "        # return the list of obstacles\n",
    "\n",
    "        with open(map_name, 'r') as file:\n",
    "            global MAP_SIZE_X\n",
    "            global MAP_SIZE_Y\n",
    "            MAP_SIZE_X = (len(file.readline())-1) * BLOCK_SIZE\n",
    "            MAP_SIZE_Y = (sum(1 for line in file)+2) * BLOCK_SIZE\n",
    "            file.seek(0)\n",
    "            map = []\n",
    "            tank2 = None\n",
    "            spawners = []\n",
    "            for y, line in enumerate(file):\n",
    "                for x, char in enumerate(line):\n",
    "                    if char == '#':\n",
    "                        map.append(Obstacle(x * BLOCK_SIZE, y * BLOCK_SIZE))\n",
    "                    elif char == '@':\n",
    "                        map.append(Obstacle(x * BLOCK_SIZE, y * BLOCK_SIZE, shootable=True, color=(0, 0, 255)))\n",
    "                    elif char == '*':\n",
    "                        map.append(Obstacle(x * BLOCK_SIZE, y * BLOCK_SIZE, destructible=True, color=(128, 0, 128)))\n",
    "                    elif char == '1':\n",
    "                        tank1 = Tank(x * BLOCK_SIZE//PIXEL_SIZE, y * BLOCK_SIZE//PIXEL_SIZE, (255, 0, 0))\n",
    "                    elif char == '2':\n",
    "                        tank2 = Tank(x * BLOCK_SIZE//PIXEL_SIZE, y * BLOCK_SIZE//PIXEL_SIZE, (0, 255, 0))\n",
    "                    elif char == '3':\n",
    "                        spawners += [TankBotSpawner(x * BLOCK_SIZE, y * BLOCK_SIZE, (0, 255, 0))]\n",
    "        if tank2 is None:\n",
    "            return map, tank1, spawners\n",
    "        return map, tank1, tank2            \n",
    "\n",
    "    def draw_hp(screen, tank1, tank2, game_state):\n",
    "        font = pygame.font.Font(None, 36)\n",
    "\n",
    "        text_surface_tank1 = font.render(f'Tank 1 HP: {tank1.health}', True, (0, 255, 0))\n",
    "        text_rect_tank1 = text_surface_tank1.get_rect()\n",
    "        text_rect_tank1.bottomleft = (PIXEL_SIZE*2, MAP_SIZE_Y-PIXEL_SIZE)\n",
    "        screen.blit(text_surface_tank1, text_rect_tank1)\n",
    "\n",
    "        if tank2 is not None:\n",
    "            text_surface_tank2 = font.render(f'Tank 2 HP: {tank2.health}', True, (0, 255, 0))\n",
    "            text_rect_tank2 = text_surface_tank2.get_rect()\n",
    "            text_rect_tank2.bottomright = (MAP_SIZE_X-PIXEL_SIZE*2, MAP_SIZE_Y-PIXEL_SIZE)\n",
    "            screen.blit(text_surface_tank2, text_rect_tank2) \n",
    "        else:\n",
    "            text_surface_points = font.render(f'Points: {game_state.points}', True, (0, 255, 0))\n",
    "            text_rect_points = text_surface_points.get_rect()\n",
    "            text_rect_points.bottomright = (MAP_SIZE_X-PIXEL_SIZE*2, MAP_SIZE_Y-PIXEL_SIZE)\n",
    "            screen.blit(text_surface_points, text_rect_points)\n",
    "            \n",
    "\n",
    "    def check_collision(object1, object2):\n",
    "        return object1.rect.colliderect(object2.rect)\n",
    "    \n",
    "    def check_nearby_objects(tank, objects):\n",
    "        rect_up = pygame.Rect(tank.x, tank.y - PIXEL_SIZE, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        rect_down = pygame.Rect(tank.x, tank.y + PIXEL_SIZE, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        rect_left = pygame.Rect(tank.x - PIXEL_SIZE, tank.y, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        rect_right = pygame.Rect(tank.x + PIXEL_SIZE, tank.y, BLOCK_SIZE, BLOCK_SIZE)\n",
    "\n",
    "        nearby_objects = [0, 0, 0, 0]\n",
    "        for object in objects:\n",
    "            if rect_up.colliderect(object.rect):\n",
    "                nearby_objects[0] = 1\n",
    "            if rect_down.colliderect(object.rect):\n",
    "                nearby_objects[1] = 1\n",
    "            if rect_left.colliderect(object.rect):\n",
    "                nearby_objects[2] = 1\n",
    "            if rect_right.colliderect(object.rect):\n",
    "                nearby_objects[3] = 1\n",
    "        return nearby_objects\n",
    "    \n",
    "    def find_closest_bot(game_state):\n",
    "        closest_bot = None\n",
    "        closest_distance = 10000\n",
    "        for bot in game_state.tank_bots:\n",
    "            distance = Utils.get_distance(game_state.tank1, bot)\n",
    "            if distance < closest_distance:\n",
    "                closest_distance = distance\n",
    "                closest_bot = bot\n",
    "        return closest_bot\n",
    "\n",
    "    def check_nearby_bullets(tank, bullets):\n",
    "        rect_up = pygame.Rect(tank.x, tank.y - BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        rect_2_up = pygame.Rect(tank.x, tank.y - 2*BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        rect_down = pygame.Rect(tank.x, tank.y + BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        rect_2_down = pygame.Rect(tank.x, tank.y + 2*BLOCK_SIZE, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        rect_left = pygame.Rect(tank.x - BLOCK_SIZE, tank.y, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        rect_2_left = pygame.Rect(tank.x - 2*BLOCK_SIZE, tank.y, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        rect_right = pygame.Rect(tank.x + BLOCK_SIZE, tank.y, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        rect_2_right = pygame.Rect(tank.x + 2*BLOCK_SIZE, tank.y, BLOCK_SIZE, BLOCK_SIZE)\n",
    "\n",
    "        nearby_bullets = [10, 10, 10, 10]\n",
    "        for bullet in bullets:\n",
    "            if rect_up.colliderect(bullet.rect) or rect_2_up.colliderect(bullet.rect):\n",
    "                distance = abs(tank.y-bullet.y)\n",
    "                nearby_bullets[0] = distance if nearby_bullets[0] > distance > 0 else nearby_bullets[0]\n",
    "            if rect_down.colliderect(bullet.rect) or rect_2_down.colliderect(bullet.rect):\n",
    "                distance = abs(tank.y-bullet.y)\n",
    "                nearby_bullets[1] = distance if nearby_bullets[1] > distance > 0 else nearby_bullets[1]\n",
    "            if rect_left.colliderect(bullet.rect) or rect_2_left.colliderect(bullet.rect):\n",
    "                distance = abs(tank.x-bullet.x)\n",
    "                nearby_bullets[2] = distance if nearby_bullets[2] > distance > 0 else nearby_bullets[2]\n",
    "            if rect_right.colliderect(bullet.rect) or rect_2_right.colliderect(bullet.rect):\n",
    "                distance = abs(tank.x-bullet.x)\n",
    "                nearby_bullets[3] = distance if nearby_bullets[3] > distance > 0 else nearby_bullets[3]\n",
    "        for i in range(4):\n",
    "            nearby_bullets[i] = -100 if nearby_bullets[i] == 10000 else nearby_bullets[i]\n",
    "        return nearby_bullets\n",
    "\n",
    "    def get_distance(object1, object2):\n",
    "        return ((object1.x - object2.x)**2 + (object1.y - object2.y)**2)**0.5\n",
    "\n",
    "class State:\n",
    "    def __init__(self, tank1, init_map, tank2=None, spawners=[]):\n",
    "        self.tank1 = tank1\n",
    "        self.tank2 = tank2\n",
    "        self.bullets = []\n",
    "        self.map = init_map\n",
    "        self.spawners = spawners\n",
    "        self.spawn_cooldown = 60\n",
    "        self.tank_bots = [self.spawn_bot_on_start()]\n",
    "        self.points = 0\n",
    "        self.max_enemies = 5\n",
    "\n",
    "    def spawn_bot_on_start(self):\n",
    "        spawner = random.choice(self.spawners)\n",
    "        return spawner.spawn()\n",
    "\n",
    "    def draw(self, screen, game_state):         \n",
    "        screen.fill((80, 80, 80))\n",
    "        self.tank1.draw(screen)\n",
    "        if self.tank2 is not None:\n",
    "            self.tank2.draw(screen)\n",
    "        else:\n",
    "            # for spawner in self.spawners:\n",
    "                # spawner.draw(screen)\n",
    "            for tank_bot in self.tank_bots:\n",
    "                tank_bot.draw(screen)\n",
    "        for obstacle in self.map:\n",
    "            obstacle.draw(screen)\n",
    "        \n",
    "        for bullet in self.bullets:\n",
    "            bullet.draw(screen)\n",
    "        Utils.draw_hp(screen, self.tank1, self.tank2, game_state)\n",
    "\n",
    "    def game_tick(self, game_state):\n",
    "        points = 0\n",
    "        took_damage = False\n",
    "        if self.tank2 is None:\n",
    "            for tank_bot in self.tank_bots:\n",
    "                if tank_bot.health == 0:\n",
    "                    self.tank_bots.remove(tank_bot)\n",
    "                    self.points += 1\n",
    "                    points += 1\n",
    "                    continue\n",
    "                tank_bot.move(game_state)\n",
    "                tank_bot.shoot(game_state)\n",
    "                tank_bot.decrease_cooldown()\n",
    "        for bullet in self.bullets:\n",
    "            bullet.move()\n",
    "            for obstacle in self.map:\n",
    "                if obstacle.shootable:\n",
    "                    continue\n",
    "                if Utils.check_collision(bullet, obstacle):\n",
    "                    if bullet in self.bullets:\n",
    "                        self.bullets.remove(bullet)\n",
    "                    if obstacle.destructible:\n",
    "                        obstacle.hp -= 1\n",
    "                        if obstacle.hp == 0:\n",
    "                            self.map.remove(obstacle)\n",
    "                    break\n",
    "            if Utils.check_collision(bullet, self.tank1):\n",
    "                self.tank1.health -= 1\n",
    "                if bullet in self.bullets:\n",
    "                    self.bullets.remove(bullet)\n",
    "                    took_damage = True\n",
    "            if self.tank2 is not None:\n",
    "                if Utils.check_collision(bullet, self.tank2):\n",
    "                    self.tank2.health -= 1\n",
    "                    if bullet in self.bullets:\n",
    "                        self.bullets.remove(bullet)\n",
    "            else:\n",
    "                if not bullet.is_from_bot:\n",
    "                    for tank_bot in self.tank_bots:\n",
    "                        if Utils.check_collision(bullet, tank_bot):\n",
    "                            tank_bot.health -= 1\n",
    "                            if bullet in self.bullets:\n",
    "                                self.bullets.remove(bullet)\n",
    "                            break\n",
    "        for bullet1 in self.bullets:\n",
    "            for bullet2 in self.bullets:\n",
    "                if bullet1 == bullet2:\n",
    "                    continue\n",
    "                if Utils.check_collision(bullet1, bullet2):\n",
    "                    self.bullets.remove(bullet1)\n",
    "                    self.bullets.remove(bullet2)\n",
    "        self.bullets = [bullet for bullet in self.bullets if 0 <= bullet.x <= MAP_SIZE_X and 0 <= bullet.y <= MAP_SIZE_Y]\n",
    "        if self.tank2 is not None:\n",
    "            if self.tank1.health == 0:\n",
    "                # print(\"Player 2 wins!\")\n",
    "                return True, took_damage, points\n",
    "            if self.tank2.health == 0:\n",
    "                # print(\"Player 1 wins!\")\n",
    "                return True, took_damage, points\n",
    "            self.tank1.decrease_cooldown()\n",
    "            self.tank2.decrease_cooldown()\n",
    "        else:\n",
    "            if self.tank1.health == 0:\n",
    "                # print(\"You lose!\")\n",
    "                # print(f\"Final score: {self.points}\")\n",
    "                return True, took_damage, points\n",
    "            self.tank1.decrease_cooldown()\n",
    "        \n",
    "            if len(self.tank_bots) < self.max_enemies and self.spawn_cooldown == 0 or len(self.tank_bots) == 0:\n",
    "                spawner = random.choice(self.spawners)\n",
    "                # check if there's any tank on the spawner\n",
    "                while any(Utils.check_collision(spawner, tank) for tank in self.tank_bots + [self.tank1]):\n",
    "                    spawner = random.choice(self.spawners)\n",
    "                self.tank_bots.append(spawner.spawn())\n",
    "                self.spawn_cooldown = 120\n",
    "        if self.spawn_cooldown > 0:\n",
    "            self.spawn_cooldown -= 1\n",
    "        return False, took_damage, points\n",
    "\n",
    "class Tank:\n",
    "    def __init__(self, x, y, color):\n",
    "        # positon\n",
    "        self.x = x * PIXEL_SIZE\n",
    "        self.y = y * PIXEL_SIZE\n",
    "\n",
    "        # movement\n",
    "        self.move_cooldown = 0\n",
    "        self.direction = (0, PIXEL_SIZE)\n",
    "        \n",
    "        # shooting\n",
    "        self.reload_time = 0\n",
    "        \n",
    "        # hp\n",
    "        self.health = 3\n",
    "\n",
    "        # skin\n",
    "        self.color = color\n",
    "\n",
    "        self.rect = pygame.Rect(self.x, self.y, BLOCK_SIZE, BLOCK_SIZE)\n",
    "\n",
    "    def move(self, direction: Direction, game_state):\n",
    "        dx, dy = direction.value\n",
    "        self.direction = direction.value\n",
    "        new_x = min(max(0, self.x + dx), MAP_SIZE_X)\n",
    "        new_y = min(max(0, self.y + dy), MAP_SIZE_Y)\n",
    "        old_rect = self.rect\n",
    "        self.rect = pygame.Rect(new_x, new_y, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        for obstacle in game_state.map + [game_state.tank1] + [game_state.tank2] + game_state.tank_bots:\n",
    "            if obstacle is None or obstacle == self:\n",
    "                continue\n",
    "            if Utils.check_collision(self, obstacle):\n",
    "                self.rect = old_rect\n",
    "                return\n",
    "        if self.move_cooldown > 0:\n",
    "            return\n",
    "        self.move_cooldown = 3\n",
    "        self.x = new_x\n",
    "        self.y = new_y\n",
    "\n",
    "    def shoot(self, game_state):\n",
    "        if self.reload_time > 0:\n",
    "            return\n",
    "        self.reload_time = 80\n",
    "        # it just works, don't ask me how\n",
    "        bullet_x = self.x + (BLOCK_SIZE ) // 2 - BULLET_SIZE // 2 + self.direction[0]//PIXEL_SIZE * BLOCK_SIZE\n",
    "        bullet_y = self.y + (BLOCK_SIZE) // 2 - BULLET_SIZE // 2 + self.direction[1]//PIXEL_SIZE * BLOCK_SIZE\n",
    "        game_state.bullets.append(Bullet(bullet_x, bullet_y, self.direction))\n",
    "\n",
    "    def decrease_cooldown(self):\n",
    "        if self.move_cooldown > 0:\n",
    "            self.move_cooldown -= 1\n",
    "        if self.reload_time > 0:\n",
    "            self.reload_time -= 1\n",
    "\n",
    "    def draw(self, screen):\n",
    "        if self.color == (255, 0, 0):\n",
    "            i = 1\n",
    "        elif self.color == (0, 255, 0):\n",
    "            i = 2\n",
    "        else:\n",
    "            i = 3\n",
    "        match self.direction:\n",
    "            case Direction.LEFT.value:\n",
    "                img = pygame.image.load(f\"lab4/assets/tank{i}_90.png\")\n",
    "            case Direction.RIGHT.value:\n",
    "                img = pygame.image.load(f\"lab4/assets/tank{i}_270.png\")\n",
    "            case Direction.UP.value:\n",
    "                img = pygame.image.load(f\"lab4/assets/tank{i}_0.png\")\n",
    "            case Direction.DOWN.value:\n",
    "                img = pygame.image.load(f\"lab4/assets/tank{i}_180.png\")\n",
    "        screen.blit(img, (self.x, self.y))\n",
    "\n",
    "class TankBot(Tank):\n",
    "    def __init__(self, x, y, color):\n",
    "        super().__init__(x//PIXEL_SIZE, y//PIXEL_SIZE, color)\n",
    "        self.turn_cooldown = 25\n",
    "        self.health = 1\n",
    "\n",
    "    def move(self, game_state):\n",
    "        if self.move_cooldown > 0:\n",
    "            return\n",
    "        if self.turn_cooldown == 0:\n",
    "            direction = random.choice(list(Direction)).value\n",
    "            self.turn_cooldown = 25\n",
    "        else:\n",
    "            direction = self.direction\n",
    "        self.move_cooldown = 5\n",
    "        self.direction = direction\n",
    "        dx, dy = self.direction\n",
    "        new_x = min(max(0, self.x + dx), MAP_SIZE_X)\n",
    "        new_y = min(max(0, self.y + dy), MAP_SIZE_Y)\n",
    "        old_rect = self.rect\n",
    "        self.rect = pygame.Rect(new_x, new_y, BLOCK_SIZE, BLOCK_SIZE)\n",
    "        for obstacle in game_state.map + [game_state.tank1] + [game_state.tank2] + game_state.tank_bots:\n",
    "            if obstacle is None or obstacle == self:\n",
    "                continue\n",
    "            if Utils.check_collision(self, obstacle):\n",
    "                self.rect = old_rect\n",
    "                return\n",
    "        self.x = new_x\n",
    "        self.y = new_y\n",
    "\n",
    "    def shoot(self, game_state):\n",
    "        if self.reload_time > 0:\n",
    "            return\n",
    "        self.reload_time = 180 \n",
    "        # it just works, don't ask me how\n",
    "        bullet_x = self.x + (BLOCK_SIZE ) // 2 - BULLET_SIZE // 2 + self.direction[0]//PIXEL_SIZE * BLOCK_SIZE\n",
    "        bullet_y = self.y + (BLOCK_SIZE) // 2 - BULLET_SIZE // 2 + self.direction[1]//PIXEL_SIZE * BLOCK_SIZE\n",
    "        game_state.bullets.append(Bullet(bullet_x, bullet_y, self.direction, is_from_bot=True, velocity=0.2))\n",
    "\n",
    "    def decrease_cooldown(self):\n",
    "        if self.move_cooldown > 0:\n",
    "            self.move_cooldown -= 1\n",
    "        if self.reload_time > 0:\n",
    "            self.reload_time -= 1\n",
    "        if self.turn_cooldown > 0:\n",
    "            self.turn_cooldown -= 1\n",
    "\n",
    "class TankBotSpawner:\n",
    "    def __init__(self, x, y, color):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.color = color\n",
    "        self.rect = pygame.Rect(self.x, self.y, BLOCK_SIZE, BLOCK_SIZE)\n",
    "\n",
    "    def spawn(self):\n",
    "        return TankBot(self.x, self.y, self.color)        \n",
    "    \n",
    "    def draw(self, screen):\n",
    "        pygame.draw.rect(screen, self.color, (self.x, self.y, BLOCK_SIZE, BLOCK_SIZE))\n",
    "\n",
    "class Bullet:\n",
    "    def __init__(self, start_x, start_y, direction, is_from_bot=False, velocity=1):\n",
    "        self.x = start_x\n",
    "        self.y = start_y\n",
    "        self.direction = direction\n",
    "        self.velocity = velocity\n",
    "        self.is_from_bot = is_from_bot\n",
    "        self.rect = pygame.Rect(self.x, self.y, BULLET_SIZE, BULLET_SIZE)\n",
    "        \n",
    "    def draw(self, screen):\n",
    "        img = pygame.image.load(\"lab4/assets/bullet.png\")\n",
    "        screen.blit(img, (self.x, self.y))\n",
    "        \n",
    "    def move(self):\n",
    "        dx, dy = self.direction\n",
    "        self.x += dx * self.velocity\n",
    "        self.y += dy * self.velocity\n",
    "        self.rect = pygame.Rect(self.x, self.y, BULLET_SIZE, BULLET_SIZE)\n",
    "\n",
    "class Obstacle:\n",
    "    def __init__(self, x, y, shootable=False, destructible=False, color=(0, 0, 0)):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.shootable = shootable\n",
    "        self.destructible = destructible\n",
    "        self.hp = 3\n",
    "        self.color = color\n",
    "        self.rect = pygame.Rect(self.x, self.y, BLOCK_SIZE, BLOCK_SIZE)\n",
    "\n",
    "    def draw(self, screen):\n",
    "        if self.destructible:\n",
    "            self.color = (255, 64*self.hp, 0)\n",
    "        pygame.draw.rect(screen, self.color, (self.x, self.y, BLOCK_SIZE, BLOCK_SIZE))\n",
    "\n",
    "def handle_key_presses(game_state: State):\n",
    "    keys = pygame.key.get_pressed()\n",
    "    if keys[pygame.K_w]:\n",
    "        game_state.tank1.move(Direction.UP, game_state)\n",
    "    elif keys[pygame.K_s]:\n",
    "        game_state.tank1.move(Direction.DOWN, game_state)\n",
    "    elif keys[pygame.K_a]:\n",
    "        game_state.tank1.move(Direction.LEFT, game_state)\n",
    "    elif keys[pygame.K_d]:\n",
    "        game_state.tank1.move(Direction.RIGHT, game_state)\n",
    "    if keys[pygame.K_SPACE]:\n",
    "        game_state.tank1.shoot(game_state)\n",
    "        closest_bot = Utils.find_closest_bot(game_state)\n",
    "        if game_state.tank1.direction == Direction.UP.value and closest_bot.y > game_state.tank1.y and abs(closest_bot.x - game_state.tank1.x) < 25 \\\n",
    "            or game_state.tank1.direction == Direction.DOWN.value and closest_bot.y < game_state.tank1.y and abs(closest_bot.x - game_state.tank1.x) < 25 \\\n",
    "            or game_state.tank1.direction == Direction.LEFT.value and closest_bot.x < game_state.tank1.x and abs(closest_bot.y - game_state.tank1.y) < 25 \\\n",
    "            or game_state.tank1.direction == Direction.RIGHT.value and closest_bot.x > game_state.tank1.x and abs(closest_bot.y - game_state.tank1.y) < 25:\n",
    "            return 3\n",
    "    return 0\n",
    "\n",
    "def handle_key_presses_AI(game_state: State, action):\n",
    "    if action[0] == 1:\n",
    "        game_state.tank1.move(Direction.UP, game_state)\n",
    "    if action[1] == 1:\n",
    "        game_state.tank1.move(Direction.DOWN, game_state)\n",
    "    if action[2] == 1:\n",
    "        game_state.tank1.move(Direction.LEFT, game_state)\n",
    "    if action[3] == 1:\n",
    "        game_state.tank1.move(Direction.RIGHT, game_state)\n",
    "    if action[4] == 1:\n",
    "        game_state.tank1.shoot(game_state)\n",
    "        closest_bot = Utils.find_closest_bot(game_state)\n",
    "        if game_state.tank1.direction == Direction.UP.value and closest_bot.y > game_state.tank1.y and abs(closest_bot.x - game_state.tank1.x) < 25 \\\n",
    "            or game_state.tank1.direction == Direction.DOWN.value and closest_bot.y < game_state.tank1.y and abs(closest_bot.x - game_state.tank1.x) < 25 \\\n",
    "            or game_state.tank1.direction == Direction.LEFT.value and closest_bot.x < game_state.tank1.x and abs(closest_bot.y - game_state.tank1.y) < 25 \\\n",
    "            or game_state.tank1.direction == Direction.RIGHT.value and closest_bot.x > game_state.tank1.x and abs(closest_bot.y - game_state.tank1.y) < 25:\n",
    "            return 3\n",
    "    return 0\n",
    "\n",
    "class TankGame:\n",
    "    def __init__(self, map_name, FPS=60):\n",
    "        self.map_name = map_name\n",
    "        init_map, tank1, spawners = Utils.init_map(map_name)\n",
    "        self.game_state = State(tank1, init_map, spawners=spawners)\n",
    "        self.screen = pygame.display.set_mode([MAP_SIZE_X, MAP_SIZE_Y])\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.FPS = FPS\n",
    "        self.init_FPS = FPS\n",
    "        self.frame_iteration = 0\n",
    "        self.cooldown = 0\n",
    "        self.human_mode = True\n",
    "        self.good_shoots = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.good_shoots = 0\n",
    "        init_map, tank1, spawners = Utils.init_map(self.map_name)\n",
    "        self.game_state = State(tank1, init_map, spawners=spawners)\n",
    "        self.frame_iteration = 0\n",
    "        self.game_state.tank_bots = [self.game_state.spawn_bot_on_start()]\n",
    "\n",
    "    def play_step(self, action):\n",
    "        self.clock.tick(self.FPS)\n",
    "        self.frame_iteration += 1\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                return False\n",
    "        keys = pygame.key.get_pressed()\n",
    "        if keys[pygame.K_h] and self.cooldown == 0:\n",
    "            self.human_mode = not self.human_mode\n",
    "            self.cooldown = 100\n",
    "        if keys[pygame.K_f] and self.cooldown == 0:\n",
    "            self.FPS = 5 if self.FPS == self.init_FPS else self.init_FPS\n",
    "            self.cooldown = 100\n",
    "        if self.cooldown > 0:\n",
    "            self.cooldown -= 1\n",
    "        reward = 0\n",
    "        shoot_points = handle_key_presses_AI(self.game_state, action)\n",
    "        is_over, took_damage, points = self.game_state.game_tick(self.game_state)\n",
    "        # nagroda za trafianie przeciwników i strzelanie, gdy czas przeładowania jest równy 0\n",
    "        # kara za otrzymanie obrażeń i strzelanie, gdy czas przeładowania jest różny od 0 (niepotrzebne strzały)\n",
    "        # porażka, gdy gracz straci całe zdrowie lub zbyt długo nie będzie niszczył przeciwników\n",
    "        if took_damage:\n",
    "            reward -= 50\n",
    "            if is_over:\n",
    "                return reward, is_over, self.game_state.points\n",
    "        if points > 0:\n",
    "            reward += 20\n",
    "        if self.frame_iteration > 1500*(self.game_state.points+1):\n",
    "            reward -= 100\n",
    "            return reward, True, self.game_state.points\n",
    "        if action[4] == 1 and 0 < self.game_state.tank1.reload_time < 79:\n",
    "            reward -= 1\n",
    "        elif action[4] == 1 and self.game_state.tank1.reload_time == 79:\n",
    "            reward += 3\n",
    "        reward += shoot_points\n",
    "        if shoot_points > 0:\n",
    "            self.good_shoots += 1\n",
    "        if self.human_mode:\n",
    "            self.game_state.draw(self.screen, self.game_state)\n",
    "            pygame.display.flip()\n",
    "        return reward, is_over, self.game_state.points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model agenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'done'))\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition.\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class Linear_QNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.qnet = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.qnet(x)\n",
    "        return x\n",
    "\n",
    "    def save(self, file_name='model.pth'):\n",
    "        model_folder_path = './model'\n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.makedirs(model_folder_path)\n",
    "        \n",
    "        file_name = os.path.join(model_folder_path, file_name)\n",
    "        torch.save(self.state_dict(), file_name)\n",
    "\n",
    "class QTrainer:\n",
    "    def __init__(self, model, target_model, lr, gamma, batch_size, memory_capacity):\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.model = model\n",
    "        self.target_model = target_model\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=self.lr)\n",
    "        self.criterion = nn.SmoothL1Loss()  # Huber loss\n",
    "        self.memory = ReplayMemory(memory_capacity)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train_step(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        transitions = self.memory.sample(self.batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), dtype=torch.bool)\n",
    "        non_final_next_states = torch.stack([s for s in batch.next_state if s is not None])\n",
    "\n",
    "        state_batch = torch.stack(batch.state)\n",
    "        action_batch = torch.stack(batch.action)\n",
    "        reward_batch = torch.stack(batch.reward)\n",
    "        \n",
    "        state_action_values = self.model(state_batch).gather(1, action_batch)\n",
    "\n",
    "        next_state_values = torch.zeros(self.batch_size)\n",
    "        next_state_values[non_final_mask] = self.target_model(non_final_next_states).max(1)[0].detach()\n",
    "        expected_state_action_values = reward_batch + (self.gamma * next_state_values)\n",
    "\n",
    "        loss = self.criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def push_to_memory(self, state, action, next_state, reward, done):\n",
    "        self.memory.push(state, action, next_state, reward, done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from model import Linear_QNet, QTrainer\n",
    "from game_logic_ai import TankGame, Direction, Utils, PIXEL_SIZE, BLOCK_SIZE\n",
    "from helper import plot\n",
    "\n",
    "# Constants\n",
    "MAX_MEMORY = 100_000\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.001\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200  # Decay parameter for epsilon\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.n_games = 0\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.epsilon = EPS_START\n",
    "        self.gamma = 0.98\n",
    "        self.memory = deque(maxlen=MAX_MEMORY)\n",
    "        self.model = Linear_QNet(state_size, 512, action_size)\n",
    "        self.target_model = Linear_QNet(state_size, 512, action_size)\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        self.target_model.eval()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=LR)\n",
    "        self.criterion = nn.SmoothL1Loss()\n",
    "\n",
    "    def get_state(self, game: TankGame):\n",
    "        # tank_location = [game.game_state.tank1.x, game.game_state.tank1.y]\n",
    "        # find closest bot, give relative cords\n",
    "        closest_bot = Utils.find_closest_bot(game.game_state)\n",
    "        bot_location = [(game.game_state.tank1.x-closest_bot.x)/100, (game.game_state.tank1.y-closest_bot.y)/100]\n",
    "        rotation = [np.sign(game.game_state.tank1.direction[0]), np.sign(game.game_state.tank1.direction[1])]\n",
    "        # iterate through all game objects, check if they are next to the tank in 4 main directions\n",
    "        nearby_objects = Utils.check_nearby_objects(game.game_state.tank1, game.game_state.tank_bots + game.game_state.map)\n",
    "        nearby_bullets = [i/100 for i in Utils.check_nearby_bullets(game.game_state.tank1, game.game_state.bullets)]\n",
    "        reload_time = 1 if game.game_state.tank1.reload_time > 0 else 0\n",
    "        state = bot_location + rotation + nearby_objects + nearby_bullets + [reload_time]\n",
    "        # state = [reload_time] + nearby_objects \n",
    "        return np.array(state, dtype=int)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            action = random.randrange(self.action_size)\n",
    "            return action\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n",
    "                action = self.model(state).max(1)[1].item()\n",
    "                return action\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def train(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        states = torch.tensor(states, dtype=torch.float)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).view(-1, 1)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float).view(-1, 1)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float)\n",
    "        dones = torch.tensor(dones, dtype=torch.bool).view(-1, 1)\n",
    "\n",
    "        current_q_values = self.model(states).gather(1, actions)\n",
    "\n",
    "        next_q_values = torch.zeros(BATCH_SIZE, dtype=torch.float)\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, next_states)), dtype=torch.bool)\n",
    "        non_final_next_states = next_states[non_final_mask]\n",
    "        with torch.no_grad():\n",
    "            next_q_values[non_final_mask] = self.target_model(non_final_next_states).max(1)[0]\n",
    "\n",
    "        expected_q_values = rewards + (self.gamma * next_q_values.unsqueeze(1))\n",
    "\n",
    "        loss = self.criterion(current_q_values, expected_q_values)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = EPS_END + (EPS_START - EPS_END) * np.exp(-1. * self.n_games / EPS_DECAY)\n",
    "\n",
    "\n",
    "def train():\n",
    "    plot_scores = []\n",
    "    plot_mean_scores = []\n",
    "    total_score = 0\n",
    "    agent = Agent(state_size=13, action_size=5)\n",
    "    total_score = 0\n",
    "    record = 0\n",
    "    game = TankGame(\"lab4/survival.txt\", FPS=600000)\n",
    "    for episode in range(1000):  # Adjust the number of episodes as needed\n",
    "        # Run episode\n",
    "        done = False\n",
    "        score = 0\n",
    "        total_reward = 0\n",
    "        # Initialize your game environment here\n",
    "        while not done:\n",
    "            state = agent.get_state(game) \n",
    "            action = agent.get_action(state)\n",
    "            final_move = [0] * 5\n",
    "            final_move[action] = 1\n",
    "            reward, done, score = game.play_step(final_move)\n",
    "            next_state = agent.get_state(game)\n",
    "\n",
    "\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            agent.train()\n",
    "            agent.update_target_model()\n",
    "\n",
    "            total_reward += reward\n",
    "\n",
    "        # Logging\n",
    "        game.reset()\n",
    "        agent.n_games += 1\n",
    "        agent.decay_epsilon()\n",
    "        if agent.n_games % 1 == 0:\n",
    "            print(f'Episode: {episode}, Total Episode Reward: {total_reward}')\n",
    "        if score > record:\n",
    "            record = score\n",
    "            agent.model.save()\n",
    "        \n",
    "        print('Game', agent.n_games, 'Score', score, 'Record', record)\n",
    "        \n",
    "        plot_scores.append(score)\n",
    "        total_score += score\n",
    "        mean_score = total_score / agent.n_games\n",
    "        plot_mean_scores.append(mean_score)\n",
    "        plot(plot_scores, plot_mean_scores)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pomocnicza funkcja do wykresów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "def plot(scores, mean_scores):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    plt.clf()\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Number of games')\n",
    "    plt.ylabel('Score')\n",
    "    plt.plot(scores)\n",
    "    plt.plot(mean_scores)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.text(len(scores)-1, scores[-1], str(scores[-1]))\n",
    "    plt.text(len(mean_scores)-1, mean_scores[-1], str(mean_scores[-1]))\n",
    "\n",
    "    plt.show(block=False)\n",
    "    plt.pause(.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intobl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

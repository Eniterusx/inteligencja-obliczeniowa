{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CarRacing-v2\", domain_randomize=True, render_mode=\"human\")\n",
    "\n",
    "# normal reset, this changes the colour scheme by default\n",
    "env.reset()\n",
    "\n",
    "# reset with colour scheme change\n",
    "env.reset(options={\"randomize\": True})\n",
    "\n",
    "# reset with no colour scheme change\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "# env.render()\n",
    "\n",
    "for _ in range(2000):\n",
    "    action = env.action_space.sample()  # agent policy that uses the observation and info\n",
    "    observation, reward, terminated, truncated, info = env.step([-0.1, 0.1, 0])\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/coado/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 55.32GB > 5.51GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d11a545d9e4d3f8b92e4760ac98686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39mmake(\u001b[39m\"\u001b[39m\u001b[39mCarRacing-v2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m SAC(\u001b[39m\"\u001b[39m\u001b[39mMlpPolicy\u001b[39m\u001b[39m\"\u001b[39m, env, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mlearn(total_timesteps\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, log_interval\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, progress_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39msac_car_racing\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdel\u001b[39;00m model \u001b[39m# remove to demonstrate saving and loading\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/stable_baselines3/sac/sac.py:307\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    299\u001b[0m     \u001b[39mself\u001b[39m: SelfSAC,\n\u001b[1;32m    300\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    306\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfSAC:\n\u001b[0;32m--> 307\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mlearn(\n\u001b[1;32m    308\u001b[0m         total_timesteps\u001b[39m=\u001b[39mtotal_timesteps,\n\u001b[1;32m    309\u001b[0m         callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    310\u001b[0m         log_interval\u001b[39m=\u001b[39mlog_interval,\n\u001b[1;32m    311\u001b[0m         tb_log_name\u001b[39m=\u001b[39mtb_log_name,\n\u001b[1;32m    312\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39mreset_num_timesteps,\n\u001b[1;32m    313\u001b[0m         progress_bar\u001b[39m=\u001b[39mprogress_bar,\n\u001b[1;32m    314\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[39m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    346\u001b[0m         \u001b[39mif\u001b[39;00m gradient_steps \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 347\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain(batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size, gradient_steps\u001b[39m=\u001b[39mgradient_steps)\n\u001b[1;32m    349\u001b[0m callback\u001b[39m.\u001b[39mon_training_end()\n\u001b[1;32m    351\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/stable_baselines3/sac/sac.py:247\u001b[0m, in \u001b[0;36mSAC.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ment_coef_optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    245\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    246\u001b[0m     \u001b[39m# Select action according to policy\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     next_actions, next_log_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactor\u001b[39m.\u001b[39maction_log_prob(replay_data\u001b[39m.\u001b[39mnext_observations)\n\u001b[1;32m    248\u001b[0m     \u001b[39m# Compute the next Q values: min over all critics targets\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     next_q_values \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mcat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic_target(replay_data\u001b[39m.\u001b[39mnext_observations, next_actions), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/stable_baselines3/sac/policies.py:173\u001b[0m, in \u001b[0;36mActor.action_log_prob\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maction_log_prob\u001b[39m(\u001b[39mself\u001b[39m, obs: PyTorchObs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[th\u001b[39m.\u001b[39mTensor, th\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 173\u001b[0m     mean_actions, log_std, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_action_dist_params(obs)\n\u001b[1;32m    174\u001b[0m     \u001b[39m# return action and associated log prob\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist\u001b[39m.\u001b[39mlog_prob_from_params(mean_actions, log_std, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/stable_baselines3/sac/policies.py:155\u001b[0m, in \u001b[0;36mActor.get_action_dist_params\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_action_dist_params\u001b[39m(\u001b[39mself\u001b[39m, obs: PyTorchObs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[th\u001b[39m.\u001b[39mTensor, th\u001b[39m.\u001b[39mTensor, Dict[\u001b[39mstr\u001b[39m, th\u001b[39m.\u001b[39mTensor]]:\n\u001b[1;32m    148\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39m    Get the parameters for the action distribution.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m        Mean, standard deviation and optional keyword arguments.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features(obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_extractor)\n\u001b[1;32m    156\u001b[0m     latent_pi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatent_pi(features)\n\u001b[1;32m    157\u001b[0m     mean_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmu(latent_pi)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/policies.py:131\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m:return: The extracted features\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m preprocessed_obs \u001b[39m=\u001b[39m preprocess_obs(obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space, normalize_images\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize_images)\n\u001b[0;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m features_extractor(preprocessed_obs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1507\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1504\u001b[0m             tracing_state\u001b[39m.\u001b[39mpop_scope()\n\u001b[1;32m   1505\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m-> 1507\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapped_call_impl\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1508\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1509\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "\n",
    "env = gym.make(\"CarRacing-v2\")\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=1000, log_interval=4, progress_bar=True)\n",
    "model.save(\"sac_car_racing\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = SAC.load(\"sac_car_racing\")\n",
    "\n",
    "env = gym.make(\"CarRacing-v2\", render_mode=\"human\")\n",
    "obs, info = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m obs \u001b[39m=\u001b[39m vec_env\u001b[39m.\u001b[39mreset()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     action, _states \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     obs, rewards, dones, info \u001b[39m=\u001b[39m vec_env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/coado/uni/inteligencja-obliczeniowa/lab6/lab6.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:556\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[1;32m    537\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    538\u001b[0m     observation: Union[np\u001b[39m.\u001b[39mndarray, Dict[\u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39mndarray]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    542\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, Optional[Tuple[np\u001b[39m.\u001b[39mndarray, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]]:\n\u001b[1;32m    543\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[39m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[39m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mpredict(observation, state, episode_start, deterministic)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/stable_baselines3/common/policies.py:368\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    365\u001b[0m obs_tensor, vectorized_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_to_tensor(observation)\n\u001b[1;32m    367\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 368\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict(obs_tensor, deterministic\u001b[39m=\u001b[39mdeterministic)\n\u001b[1;32m    369\u001b[0m \u001b[39m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[1;32m    370\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mshape))  \u001b[39m# type: ignore[misc]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/stable_baselines3/td3/policies.py:242\u001b[0m, in \u001b[0;36mTD3Policy._predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, observation: PyTorchObs, deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    240\u001b[0m     \u001b[39m# Note: the deterministic deterministic parameter is ignored in the case of TD3.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[39m#   Predictions are always deterministic.\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactor(observation)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/stable_baselines3/td3/policies.py:78\u001b[0m, in \u001b[0;36mActor.forward\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, obs: th\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     76\u001b[0m     \u001b[39m# assert deterministic, 'The TD3 actor only outputs deterministic actions'\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features(obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_extractor)\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmu(features)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlinear(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "obs = vec_env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Step 25: Memory usage: 465.25390625 MB\n",
      "Step 50: Memory usage: 466.5625 MB\n",
      "Step 75: Memory usage: 467.90234375 MB\n",
      "Step 100: Memory usage: 469.26171875 MB\n",
      "Step 125: Memory usage: 470.57421875 MB\n",
      "Step 150: Memory usage: 471.89453125 MB\n",
      "Step 175: Memory usage: 473.2109375 MB\n",
      "Step 200: Memory usage: 474.5234375 MB\n",
      "Step 225: Memory usage: 475.8359375 MB\n",
      "Step 250: Memory usage: 477.2109375 MB\n",
      "Step 275: Memory usage: 478.47265625 MB\n",
      "Step 300: Memory usage: 479.84765625 MB\n",
      "Step 325: Memory usage: 481.09765625 MB\n",
      "Step 350: Memory usage: 482.57421875 MB\n",
      "Step 375: Memory usage: 483.89453125 MB\n",
      "Step 400: Memory usage: 485.21484375 MB\n",
      "Step 425: Memory usage: 486.52734375 MB\n",
      "Step 450: Memory usage: 487.83984375 MB\n",
      "Step 475: Memory usage: 489.171875 MB\n",
      "Step 500: Memory usage: 490.48828125 MB\n",
      "Step 525: Memory usage: 491.86328125 MB\n",
      "Step 550: Memory usage: 493.11328125 MB\n",
      "Step 575: Memory usage: 494.48828125 MB\n",
      "Step 600: Memory usage: 495.80078125 MB\n",
      "Step 625: Memory usage: 497.11328125 MB\n",
      "Step 650: Memory usage: 498.42578125 MB\n",
      "Step 675: Memory usage: 499.73828125 MB\n",
      "Step 700: Memory usage: 501.0625 MB\n",
      "Step 725: Memory usage: 502.359375 MB\n",
      "Step 750: Memory usage: 503.67578125 MB\n",
      "Step 775: Memory usage: 504.98828125 MB\n",
      "Step 800: Memory usage: 506.328125 MB\n",
      "Step 825: Memory usage: 507.61328125 MB\n",
      "Step 850: Memory usage: 508.98828125 MB\n",
      "Step 875: Memory usage: 510.2421875 MB\n",
      "Step 900: Memory usage: 511.61328125 MB\n",
      "Step 925: Memory usage: 512.92578125 MB\n",
      "Step 950: Memory usage: 514.24609375 MB\n",
      "Step 975: Memory usage: 515.5625 MB\n",
      "Step 1000: Memory usage: 517.03125 MB\n",
      "Step 1025: Memory usage: 863.43359375 MB\n",
      "Step 1050: Memory usage: 864.7734375 MB\n",
      "Step 1075: Memory usage: 866.05078125 MB\n",
      "Step 1100: Memory usage: 867.3359375 MB\n",
      "Step 1125: Memory usage: 863.71484375 MB\n",
      "Step 1150: Memory usage: 865.02734375 MB\n",
      "Step 1175: Memory usage: 866.34375 MB\n",
      "Step 1200: Memory usage: 867.73046875 MB\n",
      "Step 1225: Memory usage: 869.015625 MB\n",
      "Step 1250: Memory usage: 870.3359375 MB\n",
      "Step 1275: Memory usage: 871.6484375 MB\n",
      "Step 1300: Memory usage: 872.9921875 MB\n",
      "Step 1325: Memory usage: 874.26953125 MB\n",
      "Step 1350: Memory usage: 875.6484375 MB\n",
      "Step 1375: Memory usage: 876.8984375 MB\n",
      "Step 1400: Memory usage: 878.25390625 MB\n",
      "Step 1425: Memory usage: 879.56640625 MB\n",
      "Step 1450: Memory usage: 872.87890625 MB\n",
      "Step 1475: Memory usage: 882.17578125 MB\n",
      "Step 1500: Memory usage: 883.48828125 MB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m log_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, total_timesteps, log_interval):\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     mem_usage \u001b[38;5;241m=\u001b[39m monitor_memory()\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mlog_interval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Memory usage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmem_usage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Jakub\\.conda\\envs\\intobl\\Lib\\site-packages\\stable_baselines3\\sac\\sac.py:307\u001b[0m, in \u001b[0;36mSAC.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[0;32m    300\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    306\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfSAC:\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jakub\\.conda\\envs\\intobl\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:347\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 347\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jakub\\.conda\\envs\\intobl\\Lib\\site-packages\\stable_baselines3\\sac\\sac.py:222\u001b[0m, in \u001b[0;36mSAC.train\u001b[1;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mreset_noise()\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# Action by the current actor for the sampled state\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m actions_pi, log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplay_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m log_prob\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    225\u001b[0m ent_coef_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jakub\\.conda\\envs\\intobl\\Lib\\site-packages\\stable_baselines3\\sac\\policies.py:175\u001b[0m, in \u001b[0;36mActor.action_log_prob\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    173\u001b[0m mean_actions, log_std, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_action_dist_params(obs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# return action and associated log prob\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob_from_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jakub\\.conda\\envs\\intobl\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:259\u001b[0m, in \u001b[0;36mSquashedDiagGaussianDistribution.log_prob_from_params\u001b[1;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob_from_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, mean_actions: th\u001b[38;5;241m.\u001b[39mTensor, log_std: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[th\u001b[38;5;241m.\u001b[39mTensor, th\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    258\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions_from_params(mean_actions, log_std)\n\u001b[1;32m--> 259\u001b[0m     log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m action, log_prob\n",
      "File \u001b[1;32mc:\\Users\\Jakub\\.conda\\envs\\intobl\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:239\u001b[0m, in \u001b[0;36mSquashedDiagGaussianDistribution.log_prob\u001b[1;34m(self, actions, gaussian_actions)\u001b[0m\n\u001b[0;32m    236\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mlog_prob(gaussian_actions)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# Squash correction (from original SAC implementation)\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# this comes from the fact that tanh is bijective and differentiable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m log_prob \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39msum(th\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_prob\n",
      "File \u001b[1;32mc:\\Users\\Jakub\\.conda\\envs\\intobl\\Lib\\site-packages\\torch\\_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jakub\\.conda\\envs\\intobl\\Lib\\site-packages\\torch\\_tensor.py:941\u001b[0m, in \u001b[0;36mTensor.__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 941\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_VariableFunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import psutil\n",
    "import gc\n",
    "from stable_baselines3.sac.policies import MlpPolicy\n",
    "from stable_baselines3 import SAC\n",
    "\n",
    "def monitor_memory():\n",
    "    process = psutil.Process()\n",
    "    return process.memory_info().rss / (1024 ** 2)  # Memory usage in MB\n",
    "\n",
    "env = gym.make(\"CarRacing-v2\", render_mode=\"human\")\n",
    "\n",
    "model = SAC(\n",
    "    MlpPolicy, env, verbose=1, buffer_size=10000, learning_starts=1000,\n",
    "    batch_size=64, learning_rate=0.0003, gamma=0.99, tau=0.005,\n",
    "    ent_coef=\"auto\", target_update_interval=1, gradient_steps=1,\n",
    "    action_noise=None, optimize_memory_usage=False, policy_kwargs=None,\n",
    "    device='auto', _init_setup_model=True\n",
    ")\n",
    "\n",
    "# Perform learning with memory monitoring\n",
    "total_timesteps = 2000\n",
    "log_interval = 25\n",
    "\n",
    "for step in range(0, total_timesteps, log_interval):\n",
    "    model.learn(total_timesteps=log_interval, reset_num_timesteps=False)\n",
    "    mem_usage = monitor_memory()\n",
    "    print(f\"Step {step + log_interval}: Memory usage: {mem_usage} MB\")\n",
    "    \n",
    "    # Force garbage collection to manage memory\n",
    "    gc.collect()\n",
    "\n",
    "model.save(\"sac_car_racing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/anaconda3/envs/intobl/lib/python3.11/site-packages/stable_baselines3/common/buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 5.53GB > 1.16GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n\u001b[1;32m     10\u001b[0m         obs, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/anaconda3/envs/intobl/lib/python3.11/site-packages/gymnasium/wrappers/time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/anaconda3/envs/intobl/lib/python3.11/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/intobl/lib/python3.11/site-packages/gymnasium/wrappers/env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/intobl/lib/python3.11/site-packages/gymnasium/envs/box2d/car_racing.py:576\u001b[0m, in \u001b[0;36mCarRacing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    573\u001b[0m         step_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 576\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, step_reward, terminated, truncated, {}\n",
      "File \u001b[0;32m~/anaconda3/envs/intobl/lib/python3.11/site-packages/gymnasium/envs/box2d/car_racing.py:589\u001b[0m, in \u001b[0;36mCarRacing.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/intobl/lib/python3.11/site-packages/gymnasium/envs/box2d/car_racing.py:617\u001b[0m, in \u001b[0;36mCarRacing._render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    614\u001b[0m trans \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mVector2((scroll_x, scroll_y))\u001b[38;5;241m.\u001b[39mrotate_rad(angle)\n\u001b[1;32m    615\u001b[0m trans \u001b[38;5;241m=\u001b[39m (WINDOW_W \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m0\u001b[39m], WINDOW_H \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m+\u001b[39m trans[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 617\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_road\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcar\u001b[38;5;241m.\u001b[39mdraw(\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf,\n\u001b[1;32m    620\u001b[0m     zoom,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m     mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels_list\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_pixels\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    624\u001b[0m )\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mflip(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/intobl/lib/python3.11/site-packages/gymnasium/envs/box2d/car_racing.py:678\u001b[0m, in \u001b[0;36mCarRacing._render_road\u001b[0;34m(self, zoom, translation, angle)\u001b[0m\n\u001b[1;32m    669\u001b[0m         grass\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    670\u001b[0m             [\n\u001b[1;32m    671\u001b[0m                 (GRASS_DIM \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m+\u001b[39m GRASS_DIM, GRASS_DIM \u001b[38;5;241m*\u001b[39m y \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    675\u001b[0m             ]\n\u001b[1;32m    676\u001b[0m         )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m poly \u001b[38;5;129;01min\u001b[39;00m grass:\n\u001b[0;32m--> 678\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_colored_polygon\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrass_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranslation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m# draw road\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m poly, color \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroad_poly:\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;66;03m# converting to pixel coordinates\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/intobl/lib/python3.11/site-packages/gymnasium/envs/box2d/car_racing.py:775\u001b[0m, in \u001b[0;36mCarRacing._draw_colored_polygon\u001b[0;34m(self, surface, poly, color, zoom, translation, angle, clip)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m clip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    770\u001b[0m     (\u001b[38;5;241m-\u001b[39mMAX_SHAPE_DIM \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m coord[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m WINDOW_W \u001b[38;5;241m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m-\u001b[39mMAX_SHAPE_DIM \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m coord[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m WINDOW_H \u001b[38;5;241m+\u001b[39m MAX_SHAPE_DIM)\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m coord \u001b[38;5;129;01min\u001b[39;00m poly\n\u001b[1;32m    773\u001b[0m ):\n\u001b[1;32m    774\u001b[0m     gfxdraw\u001b[38;5;241m.\u001b[39maapolygon(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, poly, color)\n\u001b[0;32m--> 775\u001b[0m     \u001b[43mgfxdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilled_polygon\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CarRacing-v2\", render_mode=\"human\")\n",
    "\n",
    "model = SAC.load(\"sac_car_racing\")\n",
    "\n",
    "obs, info = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0003\n",
    "GAMMA = 0.99\n",
    "TAU = 0.005\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./ppo_car_racing_tensorboard/PPO_2\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Create the CarRacing-v2 environment\n",
    "env = gym.make('CarRacing-v2')\n",
    "\n",
    "# Wrap the environment\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Create the PPO model\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=\"./ppo_car_racing_tensorboard/\")\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=2000, log_interval=4)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_car_racing_v2\")\n",
    "\n",
    "# To use the model later, load it with:\n",
    "# model = PPO.load(\"ppo_car_racing_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0003\n",
    "GAMMA = 0.99\n",
    "TAU = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./ppo_car_racing_tensorboard/Test_1_7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab9b7d894854afba43adb4d802ba158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 37  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 3   |\n",
      "|    total_timesteps | 128 |\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 34         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 256        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01339897 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.25      |\n",
      "|    explained_variance   | -0.00327   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.374      |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 1.25       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 35          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 384         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011698784 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.25       |\n",
      "|    explained_variance   | -0.0205     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.273       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 0.721       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 35          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 512         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018160833 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | -0.0384     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.399       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 640         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015161884 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.00694     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.486       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 768         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005453637 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.0485      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.244       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | 0.00135     |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 0.724       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 33         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 896        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01607234 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.24      |\n",
      "|    explained_variance   | 0.00292    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.28       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.00301   |\n",
      "|    std                  | 0.995      |\n",
      "|    value_loss           | 0.79       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -47          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 33           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038284832 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.24        |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.144        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 0.614        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -47         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 1152        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013005823 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 0.52        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -47         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 1280        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012856516 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | -0.363      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.241       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 0.719       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -47         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 1408        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011434725 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | -0.00565    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.278       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 0.855       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -47         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011789855 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0864      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 0.544       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -47         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 1664        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026126966 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.23       |\n",
      "|    explained_variance   | -1.74       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0561      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 0.561       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -47         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 1792        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017537437 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.00872     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00723     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -47         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 1920        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001999001 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | -0.758      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0126      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.000732   |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -59.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014983116 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | -0.515      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00689     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create the CarRacing-v2 environment\n",
    "env = gym.make('CarRacing-v2')\n",
    "# env = Monitor(env)  # To log episode rewards\n",
    "\n",
    "# Wrap the environment\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Create the PPO model\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=\"./ppo_car_racing_tensorboard/\", n_steps=256, learning_rate=LR, gamma=GAMMA, tau=TAU)\n",
    "\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=100_000, tb_log_name=\"Experiment_1\", progress_bar=True, log_interval=1)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"ppo_car_racing_v2\")\n",
    "\n",
    "# To use the model later, load it with:\n",
    "# model = PPO.load(\"ppo_car_racing_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Creating environment from the given name 'CartPole-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_car_racing_tensorboard/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 26.9     |\n",
      "|    ep_rew_mean        | 26.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 553      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.691   |\n",
      "|    explained_variance | 0.056    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 1.78     |\n",
      "|    value_loss         | 9.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 29.8     |\n",
      "|    ep_rew_mean        | 29.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 579      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.533   |\n",
      "|    explained_variance | -0.135   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 2.65     |\n",
      "|    value_loss         | 10.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 31.2     |\n",
      "|    ep_rew_mean        | 31.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 597      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.672   |\n",
      "|    explained_variance | 0.038    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.2      |\n",
      "|    value_loss         | 6.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35       |\n",
      "|    ep_rew_mean        | 35       |\n",
      "| time/                 |          |\n",
      "|    fps                | 609      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.681   |\n",
      "|    explained_variance | -0.00708 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -12.4    |\n",
      "|    value_loss         | 492      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.7     |\n",
      "|    ep_rew_mean        | 35.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 605      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.678   |\n",
      "|    explained_variance | 0.0113   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.37     |\n",
      "|    value_loss         | 5.2      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.1     |\n",
      "|    ep_rew_mean        | 35.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 578      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.597   |\n",
      "|    explained_variance | -0.0292  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.31     |\n",
      "|    value_loss         | 5.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 34.6     |\n",
      "|    ep_rew_mean        | 34.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 562      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.659   |\n",
      "|    explained_variance | 0.0071   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    value_loss         | 650      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36.3     |\n",
      "|    ep_rew_mean        | 36.3     |\n",
      "| time/                 |          |\n",
      "|    fps                | 566      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.65    |\n",
      "|    explained_variance | -0.00878 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.994    |\n",
      "|    value_loss         | 4.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 38.8     |\n",
      "|    ep_rew_mean        | 38.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 568      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.684   |\n",
      "|    explained_variance | 0.00127  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 1.05     |\n",
      "|    value_loss         | 3.57     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 38.7     |\n",
      "|    ep_rew_mean        | 38.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 574      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.69    |\n",
      "|    explained_variance | 0.00376  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 1.09     |\n",
      "|    value_loss         | 3.14     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36.2     |\n",
      "|    ep_rew_mean        | 36.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 577      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.682   |\n",
      "|    explained_variance | 0.00697  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 1        |\n",
      "|    value_loss         | 2.76     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.1     |\n",
      "|    ep_rew_mean        | 35.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 580      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.599   |\n",
      "|    explained_variance | 0.00675  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.459    |\n",
      "|    value_loss         | 2.42     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 37.8     |\n",
      "|    ep_rew_mean        | 37.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 582      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.607   |\n",
      "|    explained_variance | 0.00598  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.944    |\n",
      "|    value_loss         | 2.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 39.7     |\n",
      "|    ep_rew_mean        | 39.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 586      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.627   |\n",
      "|    explained_variance | -0.0122  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.502    |\n",
      "|    value_loss         | 1.77     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 42.7      |\n",
      "|    ep_rew_mean        | 42.7      |\n",
      "| time/                 |           |\n",
      "|    fps                | 591       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.435    |\n",
      "|    explained_variance | -0.000159 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 1.04      |\n",
      "|    value_loss         | 1.43      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 46       |\n",
      "|    ep_rew_mean        | 46       |\n",
      "| time/                 |          |\n",
      "|    fps                | 594      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.62    |\n",
      "|    explained_variance | 0.000615 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.523    |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 49.1      |\n",
      "|    ep_rew_mean        | 49.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 597       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.607    |\n",
      "|    explained_variance | -0.000216 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 0.421     |\n",
      "|    value_loss         | 0.857     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 54.6      |\n",
      "|    ep_rew_mean        | 54.6      |\n",
      "| time/                 |           |\n",
      "|    fps                | 601       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.588    |\n",
      "|    explained_variance | -0.000424 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 0.353     |\n",
      "|    value_loss         | 0.618     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 58       |\n",
      "|    ep_rew_mean        | 58       |\n",
      "| time/                 |          |\n",
      "|    fps                | 599      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.61    |\n",
      "|    explained_variance | 0.000255 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.288    |\n",
      "|    value_loss         | 0.417    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 61.1     |\n",
      "|    ep_rew_mean        | 61.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 599      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.62    |\n",
      "|    explained_variance | 0.000169 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.18     |\n",
      "|    value_loss         | 0.26     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x238141cdc10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "model = A2C(\"MlpPolicy\", \"CartPole-v1\", verbose=1, tensorboard_log=\"./ppo_car_racing_tensorboard/\")\n",
    "model.learn(total_timesteps=10_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intobl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
